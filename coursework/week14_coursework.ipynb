{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS465: Coursework Exercise 4: Part 1\n",
    "### Deadline Monday 17th Feb @ 4pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This coursework assesses the learning outcomes from Week 14.\n",
    "\n",
    "The final coursework exercise for PHYS465 is made up of 2 parts. This is part 1; part 2 will be released on Wed 12th Feb. Your submission should include both exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Instructions</font>\n",
    " * Submit your work via Moodle.\n",
    " * You must submit a fully compiled `.ipynb` file which includes all codes required to replicate your results **and** a .pdf version. \n",
    "    * **Dont forget to run every cell before submitting**\n",
    "    * You must also respond to the mandatory GenAI self-assessment questionaire. \n",
    " * Your submission must include text (in markup format) that describes what each cell does and summarises the conclusions\n",
    " * The estimated workload for this is 4-6 hours. \n",
    " \n",
    "### <font color='green'>Tips</font>\n",
    " * The last question of this exercise asks you identify a key result. **To do this you do not have to have completed all exercises**. This assessment is designed to test your reflections on the problem undertaken. \n",
    " * Don't worry too much about how your code looks - while some marks will be given for sensible coding, the focus of this assessmnt is your approach used in solving the problem, your reasoning, explanation and answer.\n",
    " * As data visualisation is a key outcome, marks will be given for well presented plots \n",
    " * Explain all your reasoning for each step. A *significant fraction* of the marks are given for explanations and discussion, as they evidence understanding of the analysis.  \n",
    " * Include all relevant lines of code including import statements and read statements. As part of the assessment your code will be run offline. \n",
    "\n",
    "### <font color='red'>WARNING</font>\n",
    " * This submission must be your own work. Please note the university's policy on plagiarism.\n",
    " * While it is acceptable (and indeed encouraged) to share ideas, you must ensure that you do not use other people's code or text, and that the reflections are your own.\n",
    " * It is acceptable to use GenAI tools for guidance on how to approach this exercise, but you must ensure that all code is written by you.\n",
    "   * Should you use GenAI in this work, then answer yes to the GenAI self-assessment. You will not be penalised for this. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "**Dataset 1**: \n",
    "\n",
    "For this exercise, I have generated some data that mimics the results of an experiment. The file of interest can be found `https://raw.githubusercontent.com/MatSmithAstro/phys465_resources/main/coursework/datasets/week14_sample_dataset.csv`. \n",
    "\n",
    "The file contains 53 measurements (`x`,`y`), each with an associated uncertainty (`y_err`)\n",
    "\n",
    "This data is expected to be well fitted by a linear function ($y=\\text{inter} + \\text{slope}\\times x$). It is your job to recover the value of $\\text{inter}$ and $\\text{slope}$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2**: \n",
    "\n",
    "Distances to type Ia supernova (SNeIa) are used to measure the size of the Universe as a function of time. The state of the art in this field is the Dark Energy Survey (DES). The latest results can be downloaded from `https://raw.githubusercontent.com/MatSmithAstro/phys465_resources/main/coursework/datasets/DES-SN5YR_HD.csv`. \n",
    "\n",
    "This dataset contains 1829 SNeIa each with a measured redshift (`zHD`), distance (`MU`) and uncertainty (`MUERR_FINAL`). \n",
    "\n",
    "In cosmology we are interested in constraining the expansion rate of the universe today (the 'Hubble constant', $H_0$), the fraction of  the Universe that is matter ($\\Omega_\\text{m}$), and the fraction that is dark energy ($\\Omega_\\lambda$). \n",
    "\n",
    "In this exercise, we will use the measured distances to estimate these parameters\n",
    "  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Part 1: Algorithm Development</font>\n",
    "\n",
    "1. Write a function that defines a linear function <div align=\"right\">**[1 mark]**</div><br>\n",
    "2. Write a function to calculate `the log likelihood` between this model and the dataset\n",
    "   * _Hint_: the equation for this can be found in the lecture notes.\n",
    "   * _Hint_: not all terms in this equation are necessary, but the more that are included, the more accurate the results will be <div align=\"right\">**[3 marks]**</div><br>\n",
    "3. From previous experience, we assume a uniform prior of $-50<\\text{inter}<50$ and $0<\\text{slope}<100$. Write a function that describes `the log prior`. A normalisation of $1e-2$ is reasonable. Combine these two functions to estimate the `log posterior`. <div align=\"right\">**[3 marks]**</div><br>\n",
    "4. Write your own Metropolis-Hastings algorithm to conduct a random walk in this (slope,intercept) parameter space\n",
    "   * _Hint_: recall that we have defined the **log posterior**: recall what happens to a ratio when logged\n",
    "   * _Hint_: given that we are working in log space, the random uniform number must also be logged\n",
    "   * _Hint_: remember to store all steps taken <div align=\"right\">**[6 marks]**</div><br>\n",
    "5. Read in dataset 1, and run an MCMC chain with 10,000 steps to constrain $\\text{inter}$ and $\\text{slope}$. From the results calculate the maximum likelihood for each parameter.\n",
    "   * _Hint_: good initial conditions are $\\text{slope} = 1.2$ and $\\text{inter} = 4.5$. A step size of 0.05 for both parameters is also appropriate <div align=\"right\">**[3 marks]**</div><br>\n",
    "6. From this output, plot the chain values against the step number to determine how many steps should be removed <div align=\"right\">**[3 marks]**</div><br>\n",
    "7. After removing 'the burn', plot marginalised histograms and a 2D distribution for this chain.\n",
    "   * _Hint_: the `corner` library is useful for this.\n",
    "   * _Hint_: the 2D distribution can be either a contour or a scatter plot <div align=\"right\">**[5 marks]**</div><br>\n",
    "\n",
    "**Maximum available**: 24\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Part 2: Estimating the cosmological parameters with MCMC </font>\n",
    "\n",
    "to estimate the cosmological parameters we can use the `astropy.cosmology` library. In particular we can load either the `astropy.cosmology.FlatLambdaCDM` or `astropy.cosmology.LambdaCDM` objects. \n",
    "\n",
    "These allow us to calculate distances given different values of $z$, $H_0$, $\\Omega_m$ and $\\Omega_\\Lambda$. (_NB_: the `flatLambdaCDM` enforces that $\\Omega_\\Lambda=1-\\Omega_m$). i.e. `LambdaCDM(H0=h, Om0=Omega_m).distmod(mu_data.zHD.values).value` will return the theoretical distance to this event. \n",
    "\n",
    "Using this module, we will determine the best-fitting values of $H_0$, $\\Omega_m$ and $\\Omega_\\Lambda$. From experience, we know that ($0.2 < \\Omega_m < 0.5$) & ($65. < H_0 < 75.$). \n",
    "\n",
    "***\n",
    "\n",
    "1. Read in the SN dataset, and make a plot of the terms of interest ($zHD$; redshift and $\\mu$ distance modulus). <div align=\"right\">**[2 marks]**</div><br>\n",
    "2. Write a function to calculate `the log likelihood` between the `FlatLambdaCDM` model and this dataset that uses the `astropy.cosmology` module.\n",
    "   * _Hint_: it is perfectly acceptable to draw on your experience in Section 1 <div align=\"right\">**[4 marks]**</div><br>\n",
    "3. Write a function to calculate the `the log prior`. Combine this with the `the log likelihood` to estimate the `log posterior`. <div align=\"right\">**[4 marks]**</div><br>\n",
    "4. Use **either** the `emcee` or `pymc` library to produce an MCMC chain for this problem.\n",
    "   * _Hint_: Recall that for these two libraries the data is input slightly differently.\n",
    "   * _Hint_: For `emcee` using the Ensemble sampler, 100 walkers is appropriate. For this sampler you must also provide initial conditions for each walker. <div align=\"right\">**[7 marks]**</div><br>\n",
    "5. Using the `corner` package, produce a `corner` plot of your results. <div align=\"right\">**[5 marks]**</div><br>\n",
    "6. **Extension:** Either:\n",
    "   * Expand this analysis to the `LambdaCDM` module.\n",
    "     * _Hint_: in this case prior of ($0.4 < \\Omega_\\Lambda < 0.9$, $0.1 < \\Omega_m < 0.5$) are reasonable. \n",
    "   * Make a plot of the data will a selection of the viable model parameters overplotted. <div align=\"right\">**[6 marks]**</div><br>\n",
    "\n",
    "**Maximum available** : 28\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Part 3: Conclusing remarks </font>\n",
    "\n",
    "1. **Summary Statement**. Write a short reflective statement (200 words max) summarising a key result from cosmological analysis in Part 2. You may include a maximum of one figure. Key topics to consider are the existence of dark energy, the consequences of removing parameters from our analysis, limitations in the dataset. A significant fraction of the marks are awarded for reflective thinking: what did you learn? If you did not make it to Part 2, then reflect on your learning from Part 1 <div align=\"right\">**[8 marks]**</div><br>\n",
    "\n",
    "**Additional Marks** Marks will be awarded for notebooks, codes and plots that are well explained and well formatted. In particular, attention will be given to sensible variable names, easy to follow comments and notebook structure. <div align=\"right\">**[6 marks]**</div><br>\n",
    "\n",
    "**Maximum available**: 14\n",
    "***\n",
    "**Maximum possible** 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
