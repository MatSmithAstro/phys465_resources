{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS465: Coursework Exercise 2\n",
    "### Deadline Monday 27th Jan @ 2pm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This coursework assesses the learning outcomes from Week 12. It is worth 20% of the overall module mark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Instructions</font>\n",
    " * Submit your work via Moodle.\n",
    " * You must submit a fully compiled `.ipynb` file which includes all codes required to replicate your results **and** a .pdf version. \n",
    "    * **Dont forget to run every cell before submitting**\n",
    "    * You must also respond to the mandatory GenAI self-assessment questionaire. \n",
    " * Your submission must include text (in markup format) that describes what each cell does and summarises the conclusions\n",
    " * The estimated workload for this is 4-6 hours. \n",
    " \n",
    "### <font color='green'>Tips</font>\n",
    " * The last question of this exercise asks you identify a key result. **To do this you do not have to have completed all exercises**. This assessment is designed to test your reflections on the problem undertaken. \n",
    " * Don't worry too much about how your code looks - while some marks will be given for sensible coding, the focus of this assessmnt is your approach used in solving the problem, your reasoning, explanation and answer.\n",
    " * As data visualisation is a key outcome, marks will be given for well presented plots \n",
    " * Explain all your reasoning for each step. A *significant fraction* of the marks are given for explanations and discussion, as they evidence understanding of the analysis.  \n",
    " * Include all relevant lines of code including import statements and read statements. As part of the assessment your code will be run offline. \n",
    "\n",
    "### <font color='red'>WARNING</font>\n",
    " * This submission must be your own work. Please note the university's policy on plagiarism.\n",
    " * While it is acceptable (and indeed encouraged) to share ideas, you must ensure that you do not use other people's code or text, and that the reflections are your own.\n",
    " * It is acceptable to use GenAI tools for guidance on how to approach this exercise, but you must ensure that all code is written by you.\n",
    "   * Should you use GenAI in this work, then answer yes to the GenAI self-assessment. You will not be penalised for this. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "**Dataset 1**: \n",
    "\n",
    "The warming of the planet as caused by human activities is one of the key aspects of climate change. The Met Office has been measuring the average temperature (combining land-surface air and sea-surface water measurements) since 1850. \n",
    "\n",
    "Every year a new catalogue is released. The 2023 catalogue can be downloaded from here: `https://raw.githubusercontent.com/MatSmithAstro/phys465_resources/main/coursework/datasets/temperature-anomaly.csv` or through Moodle.\n",
    "\n",
    "For every year, this catalogue contains : \n",
    " * `temp_diff` : the mean global temperature (in Celsius) compared to a baseline derived from data taken pre-1925. \n",
    " * `temp_upper`: an upper estimate (temp+err)\n",
    " * `temp_lower`: a lower estimate (temp-err)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2**: \n",
    "\n",
    "Independently, the Global Carbon Budget Report has been collecting information on the total amount of greenhouse gases that are released each year. \n",
    "\n",
    "The catalogue, tracaing how greenhouse gase emissions have changed over the past 150 years can be downloaded from here : `https://raw.githubusercontent.com/MatSmithAstro/phys465_resources/main/coursework/datasets/total-global-emissions.csv`. \n",
    "\n",
    "This catalogue is also released per country which can be found here : `https://raw.githubusercontent.com/MatSmithAstro/phys465_resources/main/coursework/datasets/total-emissions-bycountry.csv`.\n",
    "\n",
    "For every year the catalogue contains: \n",
    "* `AnnualCO2` : total emissions (from all sources) as measured in tonnes of carbon dioxide-equivalents\n",
    "* `AnnualCO2_err`: an uncertainty on this value \n",
    "* `logCO2` : the logarithm (in base 10) of this value\n",
    "* `logCO2_err`: an uncertainty on this value \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Exercise</font>\n",
    "\n",
    "1. Write down a suitable null hypothesis for the expected relationship between global temperature ($T_\\text{global}$) and time (in years)\n",
    "   * _Hint: Consider not only trends but also the functional form that you are expecting._<div align=\"right\">**[2 marks]**</div><br>\n",
    " \n",
    "2. Load both **global** datasets into pandas dataframes and merge them using the 'Year' key. <div align=\"right\">**[1 mark]**</div><br>\n",
    "\n",
    "3. Define two functions :\n",
    "   * $y = \\text{scale}\\times e^{(t-t_0)/tau} + \\text{offset}$\n",
    "   * $y = \\text{intercept} + \\text{slope}\\times t$\n",
    "   1. Fit both to the relationship between $T_\\text{global}$ and time.\n",
    "   2. Return both the best-fit values and calculate the $\\chi^2_\\text{red}$ statistic between the data and the model.\n",
    "   3. Using the best-fit relationships calculate when the global temperature will first exceed $2\\degree$.\n",
    "   * _Hint: an exponential function is highly sensitive. Consider offsetting the time axis prior to fitting and using an initial estimate_\n",
    "   * <font color='red'>**NB (2025jan24)**</font>: the uncertainty on $t_0$ will be huge. Either ignore it, or fix it to a value (e.g. 1850). It is also sensible to renormalise the time values: i.e. $t\\rightarrow (t-1850)/10$  \n",
    "   * _Hint: to include uncertainties, consider how to combine two estimates_ <div align=\"right\">**[6 marks]**</div><br>\n",
    "   \n",
    "5. Produce a plot with two axes: one showing excess temperature as a function of time, the other showing $\\text{CO}_2$ emissions as a function of time. Include the best-fit models for both relationships. \n",
    "   * _Hint: Remember to include uncertainties and legends_\n",
    "   * <font color='red'>**NB (2025jan24)**</font>: for this exercise, you need only plot one function per dataset <div align=\"right\">**[5 marks]**</div><br>\n",
    "\n",
    "6. Using existing tools, calculate the Spearman Rank correlation between the two datasets <div align=\"right\">**[1 mark]**</div><br>\n",
    "\n",
    "7. For one parameter in the exponential model, calculate the $\\chi^2$ statistic between the data and the model at multiple values, and using a look-up table, calculate the uncertainty on that parameter. Plot the results in a histogram. \n",
    "   * _Hint: An exponential function is sensitive, I would suggest leaving the exponent as a fixed value._\n",
    "   * _Hint: You can use the uncertainty derived from curve-fitting to estimate the values to be looped over_\n",
    "   * _Hint: For speed, loop over no more than 300 values_\n",
    "   * _Hint: The parameters in the loop can be stored in a dataframe or list_\n",
    "   * <font color='red'>**NB (2025jan24)**</font> : the lookup table can be found in the week 2 lecture notes (slide 22). consider how many variables you are varying. \n",
    "   * <font color='red'>**NB (2025jan24)**</font> : this exercise asks you to loop over a range of possible values for 1 parameter while keeping all other parameters to their best-fit values. The result will be a table of (parameter_values, chi2). The _histogram_ you are required to make is a scatter plot of this table.\n",
    "   * _Hint: The measured uncertainty will be small_ <div align=\"right\">**[15 marks]**</div><br>\n",
    "   \n",
    "8. Either:\n",
    "   1. Repeat the above test, but this time allow 2 parameters to vary. Calculate the marginalised uncertainty on each. Plot the results as a contour plot.\n",
    "   2. Repeat the above test, but for the relationship between log emissions and time. Vary both parameters in the linear function to calculate an uncertainty on each.  Plot the results as a contour plot.\n",
    "   3. By identifying the countries responsible for the majority of global emissions in the 19th century, and fitting functional forms to their emissions as a function of time, determine when (with an uncertainty) their contributions to global emissions will likely fall.\n",
    "   4. <font color='red'>**NB (2025jan24)**</font>: this exercise asks you to extend the analysis of Q6 to 2 dimensions. If you find the exponential to be too unstable, you can instead use the (more stable) linear relationship between time and `logCO2` . You will not be penalised for doing this. <div align=\"right\">**[12 marks]**</div><br>\n",
    " \n",
    "9. **Summary Statement**. Write a short statement (200 words max) summarising a key result from this work and the consequence of it. You may include a maximum of one figure. A significant fraction of the marks are awarded for  physically interpretating the results. <div align=\"right\">**[8 marks]**</div><br>\n",
    "\n",
    "**Additional Marks** Marks will be awarded for notebooks, codes and plots that are well explained and well formatted. In particular, attention will be given to sensible variable names, easy to follow comments and notebook structure. <div align=\"right\">**[6 marks]**</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
